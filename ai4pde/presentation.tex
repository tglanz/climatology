\documentclass[aspectratio=169]{beamer}

\usetheme{metropolis}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{booktabs}

\title{ML / Climatology}
\subtitle{AI Methods for Partial Differential Equations}
\author{}
\date{}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

%----------------------------------------------------------------------
\begin{frame}{Example: Barotropic Vorticity Equation}

  Governs large-scale atmospheric flow on a rotating sphere, describing how
  vorticity is advected, generated by planetary rotation, and dissipated by
  viscosity.

  \begin{equation*}
    \frac{\partial \zeta}{\partial t}
    + J(\psi, \zeta)
    + \beta \frac{\partial \psi}{\partial x}
    = \nu \nabla^2 \zeta
  \end{equation*}

  \begin{columns}[T]
    \column{0.45\textwidth}
    \begin{itemize}
      \item $\zeta$ -- relative vorticity
      \item $\psi$ -- streamfunction
    \end{itemize}
    \column{0.45\textwidth}
    \begin{itemize}
      \item $\beta$ -- meridional gradient of the Coriolis parameter
      \item $\nu$ -- viscosity coefficient ($Re = UL / \nu$)
    \end{itemize}
  \end{columns}

  \vfill
  \begin{center}
    \includegraphics[width=0.25\textwidth]{system.png}
  \end{center}

\end{frame}

%----------------------------------------------------------------------
\begin{frame}{Where is AI for PDEs?}

  \begin{center}
    \includegraphics[width=0.85\textwidth]{ai4pde.png}
  \end{center}

\end{frame}

%----------------------------------------------------------------------
\begin{frame}{Physics-Based vs Data-Driven Approaches}

  \begin{center}
    \begin{tikzpicture}[
      node distance=1.8cm,
      every node/.style={
        draw, rounded corners, minimum height=1cm, minimum width=2cm,
        text centered, font=\small
      },
      arr/.style={thick, -}
    ]
      \node (sim)  {Simulation\\(FDM/FEM)};
      \node (pinn) [right of=sim,  node distance=2.5cm] {PINN};
      \node (pino) [right of=pinn, node distance=2.5cm] {PINO};
      \node (no)   [right of=pino, node distance=2.5cm] {Neural Operator\\(FNO, DeepONet)};
      \node (nn)   [right of=no,   node distance=2.5cm] {Standard NN};

      \draw[arr] (sim)  -- (pinn);
      \draw[arr] (pinn) -- (pino);
      \draw[arr] (pino) -- (no);
      \draw[arr] (no)   -- (nn);

      \node[draw=none, above=0.5cm of sim,  font=\footnotesize\itshape] {Physics-based (no data)};
      \node[draw=none, above=0.5cm of nn,   font=\footnotesize\itshape] {Data-driven (no physics)};
    \end{tikzpicture}
  \end{center}

\end{frame}

%----------------------------------------------------------------------
\begin{frame}{Development Timeline}

  Two independent lines of work:

  \begin{itemize}
    \item \textbf{PINNs} (Raissi et al., 2019) -- embed PDE constraints into the loss function
    \item \textbf{DeepONet} (Lu et al., 2019) -- learn operators between function spaces
  \end{itemize}

  \vspace{0.5em}
  In parallel, Li et al.\ developed the \textbf{Neural Operator} framework:

  \begin{enumerate}
    \item \textbf{Graph Kernel Network} (2020) -- first attempt at PDE solution operators
    \item \textbf{FNO} (2020) -- breakthrough: kernel in Fourier space, resolution invariance
    \item \textbf{PINO} (2021) -- combine FNO with physics-informed losses
  \end{enumerate}

  \vspace{0.5em}
  Open direction: \textbf{physics-aware kernels} -- encode known physical
  structure (symmetries, conservation laws, Green's functions) into the kernel
  parameterization.

\end{frame}

%----------------------------------------------------------------------
\begin{frame}{PINN}

  A neural network trained to satisfy the PDE directly. The loss penalizes
  residuals of the governing equation at collocation points.

  \begin{equation*}
    \mathcal{L} = \mathcal{L}_{\text{data}} + \mathcal{L}_{\text{PDE}}
  \end{equation*}

  \begin{itemize}
    \item Input: coordinates $(x, t)$
    \item Output: solution $u(x, t)$
    \item Learns a single solution instance; must retrain for new parameters
  \end{itemize}

  \vfill
  \hfill{\footnotesize Raissi, Perdikaris \& Karniadakis, \textit{J.\ Comput.\ Phys.}, 2019}

\end{frame}

%----------------------------------------------------------------------
\begin{frame}{DeepONet}

  Learns a nonlinear operator mapping input functions to output functions.
  Branch network encodes the input function; trunk network encodes the query
  location.

  \begin{itemize}
    \item Input: a function (e.g., initial condition) + query coordinates
    \item Output: the solution at the query point
    \item Generalizes across input functions without retraining
  \end{itemize}

  \vfill
  \hfill{\footnotesize Lu, Jin \& Karniadakis, \textit{arXiv:1910.03193}, 2019}

\end{frame}

%----------------------------------------------------------------------
\begin{frame}{FNO -- Fourier Neural Operator}

  Parameterizes the integral kernel in Fourier space. Alternates between
  Fourier-domain convolutions (global) and pointwise nonlinearities (local).

  \begin{itemize}
    \item Input: discretized input function on a grid
    \item Output: discretized output function on a grid
    \item Resolution-invariant: train on coarse grids, evaluate on fine grids
  \end{itemize}

  \vfill
  \hfill{\footnotesize Li et al., \textit{arXiv:2010.08895}, 2020}

\end{frame}

%----------------------------------------------------------------------
\begin{frame}{PINO -- Physics-Informed Neural Operator}

  Combines the operator learning framework of FNO with the physics-informed
  loss of PINNs. Reduces the amount of simulation data needed.

  \begin{equation*}
    \mathcal{L} = \mathcal{L}_{\text{data}} + \mathcal{L}_{\text{PDE}}
  \end{equation*}

  \begin{itemize}
    \item Inherits generalization from neural operators
    \item Inherits physical consistency from PINNs
    \item Requires less data than FNO, less retraining than PINNs
  \end{itemize}

  \vfill
  \hfill{\footnotesize Li et al., \textit{arXiv:2111.03794}, 2021}

\end{frame}

%----------------------------------------------------------------------
\begin{frame}{References}

  \footnotesize
  \begin{enumerate}
    \item Raissi, M., Perdikaris, P. \& Karniadakis, G.E. (2019).
      Physics-informed neural networks. \textit{J.\ Comput.\ Phys.}, 378, 686--707.

    \item Lu, L., Jin, P. \& Karniadakis, G.E. (2019).
      DeepONet: Learning nonlinear operators. \textit{arXiv:1910.03193}.

    \item Li, Z. et al. (2020).
      Neural Operator: Graph Kernel Network for PDEs. \textit{arXiv:2003.03485}.

    \item Li, Z. et al. (2020).
      Fourier Neural Operator for Parametric PDEs. \textit{arXiv:2010.08895}.

    \item Li, Z. et al. (2021).
      Neural Operator: Learning Maps Between Function Spaces. \textit{arXiv:2108.08481}.

    \item Li, Z. et al. (2021).
      Physics-Informed Neural Operator for Learning PDEs. \textit{arXiv:2111.03794}.

    \item Sahin et al. (2024).
      AI for PDEs in Computational Mechanics: A Review. \textit{arXiv:2410.19843}.
  \end{enumerate}

\end{frame}

\end{document}
